{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://datasciencedegree.wisconsin.edu/wp-content/themes/data-gulp/images/logo.svg\" width=\"300\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1. Introduction\n",
    "\n",
    "The first problem has you write some functions in order to be able to do statistics on arbitrary text.  First, we'll write a function determining the length of each word in a given sentence.  Second, we'll apply that function to some given text.  Third, we'll use it to solve a larger problem: determine properties of each sentence in a Jane Austin book.\n",
    "\n",
    "## Problem 1(a).  Word length\n",
    "\n",
    "üéØ Write a function called ```word_length_list()``` which takes a string and returns a list with the length of each word in the string.  \n",
    "\n",
    "For each word, count the number of English, alphanumeric characters.  Words are defined as text separated by spaces. Your function should ignore punctuation.  For example, ```word_length_list(\"Haven't you eaten 8 oranges today?\")``` should return ```[6,3,5,1,7,5]```.  \n",
    "\n",
    "* Call or create other functions as necessary to organize your work.\n",
    "* Write your own code to do this from first principles.  This means using Python built-in functions for splitting text, checking whether characters are punctuation, etc.  \n",
    "* Do *not* use Python packages (like nltk) or code directly copied from online resources (such as regular expressions for splitting text) in order to divide sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def word_length_list(Sentence):\n",
    "    Sentence = \"\".join(c for c in Sentence if c not in string.punctuation) #\n",
    "    Sentence = list(map(len,Sentence.split())) #output set as list, apply to each iterable item in len sentence\n",
    "    return Sentence #return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 3, 5, 1, 7, 5]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this line will run clean when you have solved the problem.\n",
    "word_length_list(\"Haven't you eaten 8 oranges today?\")\n",
    "# be sure to restart the kernel and run all cells before committing.  \n",
    "# this ensures the most recent state is what you think it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1(b).  Application -- \"A Mourner.\"\n",
    "\n",
    "The text below is an anonymous essay published in The Boston Gazette and Country Journal on January 8, 1770. \n",
    "\n",
    ">The general Sympathy and Concern for the Murder of the Lad by the base and infamous Richardson on the 22d Instant, will be sufficient Reason for your Notifying the Public that he will be buried from his Father‚Äôs House in Frogg Lane, opposite Liberty-Tree, on Monday next, when all the Friends of Liberty may have an Opportunity of paying their last Respects to the Remains of this little Hero and first Martyr to the noble Cause--Whose manly Spirit (after this Accident happened) appear‚Äôd in his discreet Answers to his Doctor, his Thanks to the Clergymen who prayed with him, and Parents, and while he underwent the greatest Distress of bodily Pain; and with which he met the King of Terrors.  These Things, together with the several heroic Pieces found in his Pocket, particularly Wolfe‚Äôs Summit of human Glory, gives Reason to think he had a martial Genius, and would have made a clever Man.\n",
    "\t\t\t\t\t\n",
    "> A Mourner.\n",
    "\n",
    "(Source:  Michael Sullivan, _Statistics:  Informed Decisions Using Data_, 4th ed.  p. 188-189.)\n",
    "\n",
    "üéØ Use your function ```word_length_list()``` from 1(a) to find the length of each word in \"A Mourner\". (Note that your output should end in . . ., 3, 1, 7].)\n",
    "\n",
    "###### Notes\n",
    "\n",
    "* check out `%pprint`.  It turns off printing each list element on a separate row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 7, 8, 3, 7, 3, 3, 6, 2, 3, 3, 2, 3, 4, 3, 8, 10, 2, 3, 3, 7, 4, 2, 10, 6, 3, 4, 9, 3, 6, 4, 2, 4, 2, 6, 4, 3, 8, 5, 2, 5, 4, 8, 11, 2, 6, 4, 4, 3, 3, 7, 2, 7, 3, 4, 2, 11, 2, 6, 5, 4, 8, 2, 3, 7, 2, 4, 6, 4, 3, 5, 6, 2, 3, 5, 10, 5, 6, 5, 4, 8, 8, 8, 2, 3, 8, 7, 2, 3, 6, 3, 6, 2, 3, 9, 3, 6, 4, 3, 3, 7, 3, 5, 2, 9, 3, 8, 8, 2, 6, 4, 3, 4, 5, 2, 3, 3, 4, 2, 7, 5, 6, 8, 4, 3, 7, 6, 6, 5, 2, 3, 6, 12, 7, 6, 2, 5, 5, 5, 6, 2, 5, 2, 3, 1, 7, 6, 3, 5, 4, 4, 1, 6, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "Mourner_essay = \"The general Sympathy and Concern for the Murder of the Lad by the base and infamous Richardson on the 22d Instant, will be sufficient Reason for your Notifying the Public that he will be buried from his Father‚Äôs House in Frogg Lane, opposite Liberty-Tree, on Monday next, when all the Friends of Liberty may have an Opportunity of paying their last Respects to the Remains of this little Hero and first Martyr to the noble Cause--Whose manly Spirit (after this Accident happened) appear‚Äôd in his discreet Answers to his Doctor, his Thanks to the Clergymen who prayed with him, and Parents, and while he underwent the greatest Distress of bodily Pain; and with which he met the King of Terrors. These Things, together with the several heroic Pieces found in his Pocket, particularly Wolfe‚Äôs Summit of human Glory, gives Reason to think he had a martial Genius, and would have made a clever Man.A Mourner.\"\n",
    "print(word_length_list(Mourner_essay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1(c). _Pride and Prejudice_.\n",
    "\n",
    "This problem is a bit bigger than parts (a) and (b), and requires some bigger thinking.  You'll have to write loops and possibly list comprehensions to solve it!\n",
    "\n",
    "üéØ Create a function \n",
    "```collect_statistics``` \n",
    "to count the number of words and mean length of words in each sentence of *Pride and Prejudice*.  We have provided `pride.txt` file in the repo, which is available without restrictions from [Project Gutenberg](https://www.gutenberg.org/).  \n",
    "\n",
    "###### Suggestions\n",
    "\n",
    "* You should use the `word_length_list` function from 1(a) in your solution.\n",
    "* Create additional functions as necessary to organize your work.\n",
    "\n",
    "Before you start programming, I suggest you compute the answers by hand, for the first few sentences of *Pride and Prejudice*.  Be sure you go far enough in the file to encounter a few anomalies!  This will give you a sense of\n",
    "  * How to solve the problem using a computer.  Make the computer do what you did!  \n",
    "  * What the answer looks like, in that you will know the first few terms in the data set you are constructing.\n",
    "\n",
    "###### Requirements and notes\n",
    "\n",
    "\n",
    "* A sentence ends with a period, exclamation point, or question mark. A hyphen, dash, or apostrophe does not end a sentence. Quotation marks do not end a sentence. But also, some periods do not end sentences. For example, Mrs., Mr., Dr., Fr., Jr., St., are all commonly occurring abbreviations that almost never end sentences, and they occur enough in Pride and Prejudice that you need to deal with them or your averages will be impacted significantly. An ellipsis sometimes ends a sentence and sometimes does not, but for this assignment you may assume an ellipsis ends a sentence (but note it does not end 3 sentences!) \n",
    "* Do *not* use Python packages (like nltk) or code directly copied from online resources (such as regular expressions for splitting text) in order to divide sentences. Write your own code to do this from first principles.\n",
    "* The mean length of words in the sample sentence from 1(a) ```\"Haven't you eaten 8 oranges today?\"``` is 4.5.\n",
    "\n",
    "###### Output\n",
    "\n",
    "* Include comments to explain the purpose and arguments of each function you create.\n",
    "* Save your result as a ```.csv``` file and include it with your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def collect_statistics(sentence_replacer): #replacing stuff that may create errors in word count \n",
    "    sentence_replacer = (\"Mr.\",\"Mr\")\n",
    "    sentence_replacer = (\"Mrs.\",\"Mrs\")\n",
    "    sentence_replacer = (\"Ms.\", \"Ms\")\n",
    "    sentence_replacer = (\"Dr.\",\"Dr\")\n",
    "    sentence_replacer = (\"Fr.\",\"Fr\")\n",
    "    sentence_replacer = (\"Jr.\", \"Jr\")\n",
    "    sentence_replacer = (\"St.\", \"St\")\n",
    "    sentence_replacer = (\"Sr.\",\"Sr\")\n",
    "    sentence_replacer = (\"...\", \".\")\n",
    "    sentence_replacer = (\"?\", \".\")\n",
    "    sentence_replacer = (\"!\", \".\")\n",
    "    sentence_replacer = (\".‚Äù\", \"\")\n",
    "    sentence_replacer = (\"?‚Äù\", \"\")\n",
    "    \n",
    "    \n",
    "    sentence_splitter = sentence_replacer.split(\".\")  #string into a list of strings on period character\n",
    "    #filter out any ending spaces\n",
    "    sentence_splitter = list(filter(lambda x: x != \"\", sentence_splitter)) #use of lambda and list function to filter ending spaces\n",
    "    \n",
    "    for i in range(len(sentence_splitter)):\n",
    "        word_count = sentence_splitter[i].split() #move through each word of sentence after splitting \n",
    "        \n",
    "        #call back earlier function from part a to find word length \n",
    "        words_length = word_length_list(sentence_splitter[i])\n",
    "        #make sure there are words in a sentence \n",
    "        if len(words_length)!= 0 :\n",
    "            # mean is sum of all the letters in a word and all the words added divided by the number or words in a sentence\n",
    "            words_mean = sum(words_length)/(len(words_length))\n",
    "            #put together words and the mean of the words to the file called sentence_splitter\n",
    "            sentence_splitter.append(len(words_length),words_mean)\n",
    "            \n",
    "import csv \n",
    "sentence_splitter = []\n",
    "    #write a file to csv        \n",
    "with open(\"PrideAndPrejudice.csv\", \"w\", newline=\"\") as PridePrejudice:\n",
    "    writer = csv.writer(PridePrejudice)\n",
    "    writer.writerows(sentence_splitter)\n",
    "#find location of pride.txt       \n",
    "with open(\"pride.txt\", encoding=\"utf8\") as PnP: \n",
    "    pride_and_prejudice = PnP.read()\n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Problem 2.  Introduction \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/English_letter_frequency_%28alphabetic%29.svg/600px-English_letter_frequency_%28alphabetic%29.svg.png\" width=\"300\">\n",
    "\n",
    "Here we will be counting e's in text files, capitalized and uncapitalized, and accented and unaccented.\n",
    "\n",
    "üéØ Your code in 2(b) must include a function called \n",
    "```\n",
    "    count_letter_e(filename, ignore_accents, ignore_case)\n",
    "    ```\n",
    "    \n",
    "  That is, `count_letter_e`:\n",
    "  * takes a filename, such as ```\"pg1342.txt\"```, as input, and \n",
    "  * returns the number of _e_'s as output. \n",
    "  * includes two optional arguments, ```ignore_accents``` and ```ignore_case```.\n",
    "    * When ```ignore_accents = True```, your function should count accented characters such as _√©_, _√™_, and _√®_ as the same as _e_.  \n",
    "    * When ```ignore_case=True```, your function should treat uppercase and lowercase _e_ as the same letter.\n",
    "* The function ```count_letter_e()``` should return a *single number*, the total number of all characters that are being treated as equivalent to _e_.\n",
    "* Create other functions as necessary to organize your work.\n",
    "* Include comments which explain the purpose and arguments of each function you create.\n",
    "* The files are encoded as [utf-8](https://en.wikipedia.org/wiki/UTF-8). When reading the files, you may have to specify the encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 2(a).  Design a Test Suite\n",
    "\n",
    "üéØ Design a test suite (which will be in this case a set of input text) of at least four sentences that will allow you to quickly verify that all four optional argument possibilities are implemented correctly. Make sure that your test suite contains at least one of each of the 8 possible e's (e, √©, √™, √®, E, √â, √ä, √à).\n",
    "\n",
    "üéØ Save your test suite as a set of text files (1 sentence per text file) for use in your ```count_letter_e()``` function, and also include each test sentence in a different markdown cell below. For each sentence, count each type of e by hand and report (in the markdown cell) what the output should be for the four possible combinations of true and false for ```ignore_case``` and ```ignore_accents```.\n",
    "\n",
    "*Note that you can complete this portion before you have written a single line of code for your function ```count_letter_e()```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sentence 1:\n",
    "  * Sentence:  The word for coffee in spanish is Caf√©\n",
    "  * Count with `ignore_case=True, ignore_accents=True`: 4\n",
    "  * Count with `ignore_case=True, ignore_accents=False`:3\n",
    "  * Count with `ignore_case=False, ignore_accents=True`:4\n",
    "  * Count with `ignore_case=False, ignore_accents=False`:3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sentence 2:\n",
    "  * Sentence: The chanc√™s of g√©tting the job ar√® very slim\n",
    "  * Count with `ignore_case=True, ignore_accents=True`: 5\n",
    "  * Count with `ignore_case=True, ignore_accents=False`:2\n",
    "  * Count with `ignore_case=False, ignore_accents=True`:5\n",
    "  * Count with `ignore_case=False, ignore_accents=False`:2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sentence 3:\n",
    "* Sentence: Data sciEnce will drive busin√âss in the future\n",
    "* Count with `ignore_case=True, ignore_accents=True`: 5\n",
    "* Count with `ignore_case=True, ignore_accents=False`:4\n",
    "* Count with `ignore_case=False, ignore_accents=True`:3\n",
    "* Count with `ignore_case=False, ignore_accents=False`:3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sentence 4:\n",
    "* Sentence: My dream is to be a ch√äif scientist at a v√àry notable company \n",
    "* Count with `ignore_case=True, ignore_accents=True`: 6\n",
    "* Count with `ignore_case=True, ignore_accents=False`:4\n",
    "* Count with `ignore_case=False, ignore_accents=True`:4\n",
    "* Count with `ignore_case=False, ignore_accents=False`:4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ Describe how you can use your four test sentences to detect problems in your implementation of `count_letter_e()`.  Why do you need four sentences, and not just one, or as many as 16?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2(b). Create and Test Your Code\n",
    "\n",
    "üéØ Create the functions described in Problem 2 Introduction, and apply them to your test suite from 2(a).  Do *not* use Python packages or code directly copied from online resources.  Write your own functions from first principles.\n",
    "\n",
    "üéØ Print the results of applying the four combinations of optional arguments of your ```count_letter_e()``` function to your test suite. Verify that the output is correct. (If it isn't, modify your code until your function works correctly on your test suite.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_letter_e(filename,ignore_accents,ignore_case):\n",
    "    \n",
    "  #find the location of the file  \n",
    "    with open(filename, 'r', encoding='utf8') as countingletter:\n",
    "        letter_counts_e =countingletter.read()\n",
    "        \n",
    "# Test case ignore accents \n",
    "#convert e with accent to normal e so there is only one type of e to read\n",
    "# replace any type of e that is not just e\n",
    "    if (ignore_accents) == True : \n",
    "        letter_counts_e = letter_counts_e.replace(\"√©\", \"e\")\n",
    "        letter_counts_e = letter_counts_e.replace(\"√™\", \"e\")\n",
    "        letter_counts_e = letter_counts_e.replace(\"√®\", \"e\")\n",
    "# take every e in uppercase and convert it to lowercase        \n",
    "    if ignore_case == True :\n",
    "        letter_counts_e=letter_counts_e.lower()\n",
    "#set variable count of e to the amout of e's counted in the file name counted letters of e         \n",
    "    count_of_e = letter_counts_e.count(\"e\")\n",
    "#return variable amount     \n",
    "    return count_of_e\n",
    "\n",
    "\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2(c). Apply Your Code\n",
    "\n",
    "üéØ Apply your code from 2(b) to the two provided `.txt` files for _Pride and Prejudice_  and _L'Enl√®vement de la redoute_. \n",
    "üéØ For each file, print the output of all four combinations of the boolena arguments to `count_letter_e`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69372\n",
      "68641\n",
      "69372\n",
      "68641\n",
      "1485\n",
      "1469\n",
      "1289\n",
      "1273\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#use print statements to count e's in the two txt files\n",
    "\n",
    "print(count_letter_e(\"pride.txt\", True, True))\n",
    "print(count_letter_e(\"pride.txt\", True, False))\n",
    "print(count_letter_e(\"pride.txt\", False, True))\n",
    "print(count_letter_e(\"pride.txt\", False, False))\n",
    "\n",
    "print(count_letter_e(\"l'enlevement.txt\", True, True))\n",
    "print(count_letter_e(\"l'enlevement.txt\", True, False))\n",
    "print(count_letter_e(\"l'enlevement.txt\", False, True))\n",
    "print(count_letter_e(\"l'enlevement.txt\", False, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
